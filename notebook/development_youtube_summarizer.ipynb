{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "class YoutubeChannelSubtitles:\n",
    "    def __init__(self, api_key):\n",
    "        self.youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "        \n",
    "    def get_channel_id(self, channel_name):\n",
    "        \"\"\"Gets the channel ID from the channel name\"\"\"\n",
    "        request = self.youtube.search().list(\n",
    "            q=channel_name,\n",
    "            type='channel',\n",
    "            part='id',\n",
    "            maxResults=1\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        if response['items']:\n",
    "            return response['items'][0]['id']['channelId']\n",
    "        return None\n",
    "\n",
    "    def get_recent_videos(self, channel_id, max_results=50, days_back=7):\n",
    "        \"\"\"Gets videos from the channel published in the last X days\"\"\"\n",
    "        # Request more videos than needed to ensure we have enough after filtering\n",
    "        request = self.youtube.search().list(\n",
    "            channelId=channel_id,\n",
    "            order='date',  # Sort by date\n",
    "            part='snippet',\n",
    "            maxResults=max_results,  # Request more to filter afterward\n",
    "            type='video'\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        videos = []\n",
    "        # Calculate cutoff date (7 days ago from now)\n",
    "        from datetime import datetime, timedelta\n",
    "        cutoff_date = datetime.now() - timedelta(days=days_back)\n",
    "        \n",
    "        for item in response['items']:\n",
    "            # Convert published date string to datetime object\n",
    "            published_at = datetime.strptime(\n",
    "                item['snippet']['publishedAt'], \n",
    "                '%Y-%m-%dT%H:%M:%SZ'\n",
    "            )\n",
    "            \n",
    "            # Only include videos published after the cutoff date\n",
    "            if published_at >= cutoff_date:\n",
    "                video = {\n",
    "                    'title': item['snippet']['title'],\n",
    "                    'video_id': item['id']['videoId'],\n",
    "                    'published_at': item['snippet']['publishedAt']\n",
    "                }\n",
    "                videos.append(video)\n",
    "        \n",
    "        return videos\n",
    "\n",
    "    def download_subtitles(self, video_id, languages=['es', 'en'], output_dir='subtitles'):\n",
    "        \"\"\"Downloads subtitles for a video in the specified languages\"\"\"\n",
    "        try:\n",
    "            # Create directory if it doesn't exist\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "            results = {}\n",
    "            \n",
    "            for language in languages:\n",
    "                try:\n",
    "                    transcript = transcript_list.find_transcript([language])\n",
    "                    subtitles = transcript.fetch()\n",
    "                    \n",
    "                    # Save in JSON format\n",
    "                    filename = f'{output_dir}/{video_id}_{language}.json'\n",
    "                    with open(filename, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(subtitles, f, ensure_ascii=False, indent=2)\n",
    "                    \n",
    "                    results[language] = 'Success'\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    results[language] = f'Failed: {str(e)}'\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f'Failed to get subtitles: {str(e)}'\n",
    "\n",
    "    def process_channel(self, channel_name, max_videos=50, languages=['es', 'en'], days_back=7):\n",
    "        \"\"\"Processes videos from a channel within the specified time frame\"\"\"\n",
    "        # Get channel ID\n",
    "        channel_id = self.get_channel_id(channel_name)\n",
    "        if not channel_id:\n",
    "            return f\"Channel not found: {channel_name}\"\n",
    "\n",
    "        # Get recent videos from the last X days\n",
    "        videos = self.get_recent_videos(channel_id, max_videos, days_back)\n",
    "        \n",
    "        if not videos:\n",
    "            return f\"No videos found in the last {days_back} days for channel: {channel_name}\"\n",
    "        \n",
    "        results = []\n",
    "        for video in videos:\n",
    "            result = {\n",
    "                'title': video['title'],\n",
    "                'video_id': video['video_id'],\n",
    "                'published_at': video['published_at'],\n",
    "                'subtitles': self.download_subtitles(video['video_id'], languages)\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        # Save results to a log file\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        with open(f'results_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        return results\n",
    "\n",
    "    def process_channel_to_csv(self, channel_name, max_videos=5, days_back=7):\n",
    "        \"\"\"Processes videos from the last X days and creates a CSV with subtitles\"\"\"\n",
    "        # Get channel ID\n",
    "        channel_id = self.get_channel_id(channel_name)\n",
    "        if not channel_id:\n",
    "            return f\"Channel not found: {channel_name}\"\n",
    "\n",
    "        # Get videos from the last X days\n",
    "        videos = self.get_recent_videos(channel_id, max_videos, days_back)\n",
    "        \n",
    "        if not videos:\n",
    "            return f\"No videos found in the last {days_back} days for channel: {channel_name}\"\n",
    "        \n",
    "        # List to store data\n",
    "        data = []\n",
    "        \n",
    "        for video in videos:\n",
    "            video_id = video['video_id']\n",
    "            title = video['title']\n",
    "            # Convert date to a more readable format\n",
    "            date = datetime.strptime(video['published_at'], '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d')\n",
    "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "            \n",
    "            try:\n",
    "                # Get subtitles\n",
    "                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "                \n",
    "                # Try manual subtitles first\n",
    "                try:\n",
    "                    transcript = transcript_list.find_manually_created_transcript()\n",
    "                except:\n",
    "                    # If no manual subtitles, try with any available language\n",
    "                    transcript = transcript_list.find_transcript(['en', 'es'])\n",
    "                \n",
    "                subtitles = transcript.fetch()\n",
    "                language = transcript.language\n",
    "                \n",
    "                # Get text from each subtitle entry\n",
    "                subtitle_texts = [entry['text'] for entry in subtitles]\n",
    "                \n",
    "                # Clean special characters from each text segment\n",
    "                cleaned_texts = []\n",
    "                for text in subtitle_texts:\n",
    "                    # Replace newlines with spaces\n",
    "                    cleaned_text = text.replace('\\n', ' ')\n",
    "                    # Replace escaped backslashes\n",
    "                    cleaned_text = cleaned_text.replace('\\\\', '')\n",
    "                    # Replace multiple spaces with a single space\n",
    "                    import re\n",
    "                    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "                    # Remove any other special characters if needed\n",
    "                    # cleaned_text = re.sub(r'[^\\w\\s.,!?;:\\-\\'\"]', '', cleaned_text)\n",
    "                    cleaned_texts.append(cleaned_text)\n",
    "                \n",
    "                # Join all cleaned text segments with spaces\n",
    "                full_text = ' '.join(cleaned_texts).strip()\n",
    "                \n",
    "                # Add to data list\n",
    "                data.append({\n",
    "                    'Title': title,\n",
    "                    'Date': date,\n",
    "                    'Text': full_text,\n",
    "                    'Link': video_url,\n",
    "                    'Language': language\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing video {video_id}: {str(e)}\")\n",
    "                \n",
    "        # Create DataFrame and save as CSV\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df[['Title', 'Date', 'Text', 'Link', 'Language']]\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        csv_filename = f'subtitles_{timestamp}.csv'\n",
    "        df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV generado: No videos found in the last 7 days for channel: @veritasium\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    API_KEY = 'AIzaSyDKckSI_0asveDz4lHuU_KMrmmU9zy0-18'\n",
    "    yt = YoutubeChannelSubtitles(API_KEY)\n",
    "    \n",
    "    csv_file = yt.process_channel_to_csv(\n",
    "        channel_name=\"@veritasium\",\n",
    "        max_videos=5,\n",
    "        days_back=7\n",
    "    )\n",
    "    \n",
    "    print(f\"CSV generado: {csv_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No videos found in the last 7 days for channel: @veritasium'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
